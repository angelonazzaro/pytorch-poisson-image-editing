{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "import pietorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Poisson image editing examples\n",
    "## Image (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_1_png = Image.open('example_images/mug.png')\n",
    "img_1 = Image.new(\"RGB\", img_1_png.size, (255, 255, 255))\n",
    "img_1.paste(img_1_png, mask=img_1_png.getchannel('A'))\n",
    "\n",
    "img_2 = Image.open('example_images/brick_texture.jpg')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "ax[0].imshow(img_1)\n",
    "ax[1].imshow(img_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = TF.to_tensor(img_1)\n",
    "\n",
    "source = TF.resize(TF.to_tensor(img_2), [512, 512])\n",
    "\n",
    "corner_coord = torch.tensor([144, 100])\n",
    "\n",
    "# mask = torch.zeros(source.shape[1:])\n",
    "# for i in range(mask.shape[0]):\n",
    "#     for j in range(mask.shape[1]):\n",
    "#         if ((i - 256) ** 2 + (j - 256) ** 2) ** 0.5 < 200:\n",
    "#             mask[i, j] = 1\n",
    "mask = torch.ones(source.shape[1:])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "ax[0].imshow(torch.movedim(target, 0, -1))\n",
    "ax[1].imshow(torch.movedim(source, 0, -1))\n",
    "ax[2].imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "res = pietorch.blend(target, source, torch.zeros(source.shape[1:]), corner_coord, True, channels_dim=0)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.imshow(torch.movedim(res, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "recon_diff = torch.abs(res - target)\n",
    "\n",
    "print(torch.min(recon_diff), '-', torch.mean(recon_diff), '/', torch.median(recon_diff), '-', torch.max(recon_diff))\n",
    "\n",
    "plt.imshow(torch.movedim(recon_diff, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "res = pietorch.blend(target, source, mask, corner_coord, True, channels_dim=0)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(torch.movedim(res, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diff = torch.abs(res - target)\n",
    "print(torch.max(diff))\n",
    "plt.imshow(torch.movedim(diff, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "res_wide = pietorch.blend_wide(target, source, mask, corner_coord, True, channels_dim=0)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(torch.movedim(res_wide, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "diff_wide = torch.abs(res_wide - target)\n",
    "print(torch.max(diff_wide))\n",
    "plt.imshow(torch.movedim(diff_wide, 0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example of using cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pietorch import CachedPoissonBlender\n",
    "\n",
    "# Add green function to cache ahead of time\n",
    "cached_blender = CachedPoissonBlender([(source.shape, 0)])\n",
    "\n",
    "start = time()\n",
    "res = cached_blender.blend(target, source, mask, corner_coord, True, channels_dim=0)\n",
    "print('Took ', time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2D OpenCV comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cv_img_1 = np.array(img_1)\n",
    "cv_img_2 = np.array(TF.resize(img_2, [512, 512]))\n",
    "cv_mask = mask.numpy().astype(np.uint8) * 255\n",
    "cv_centre_coord = (corner_coord.numpy() + np.array(cv_mask.shape) // 2)\n",
    "\n",
    "start = time()\n",
    "cv_res = cv2.seamlessClone(cv_img_2,\n",
    "                           cv_img_1,\n",
    "                           cv_mask,\n",
    "                           tuple(cv_centre_coord[::-1]),\n",
    "                           cv2.NORMAL_CLONE)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_diff = np.abs(cv_img_1.astype(int) - cv_res.astype(int))\n",
    "print(np.max(cv_diff))\n",
    "\n",
    "plt.imshow(cv_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "cv_res = cv2.seamlessClone(cv_img_2,\n",
    "                           cv_img_1,\n",
    "                           cv_mask,\n",
    "                           tuple(cv_centre_coord[::-1]),\n",
    "                           cv2.MIXED_CLONE)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_diff = np.abs(cv_img_1.astype(int) - cv_res.astype(int))\n",
    "print(np.max(cv_diff))\n",
    "\n",
    "plt.imshow(cv_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Numpy interface example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply to OpenCV data, as is already np.ndarray's\n",
    "\n",
    "np_target = cv_img_1.astype(float)\n",
    "np_source = cv_img_2.astype(float)\n",
    "np_mask = mask.numpy()\n",
    "np_corner_coord = corner_coord.numpy()\n",
    "\n",
    "start = time()\n",
    "np_res = pietorch.blend_numpy(np_target, np_source, np_mask, np_corner_coord, True, channels_dim=-1)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(np_res / 255)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np_diff = np.abs(np_res - cv_res)\n",
    "print(np.max(np_diff))\n",
    "\n",
    "plt.imshow(np_diff / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Try DST implementation (same as OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "dst_res = pietorch.blend_dst_numpy(np_target, np_source, np_mask, np_corner_coord, True, channels_dim=-1)\n",
    "print('Took ', time() - start)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dst_res / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dst_diff = np.abs(dst_res - cv_res)\n",
    "print(np.max(dst_diff))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dst_diff / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "\n",
    "axes[0].set_title('Numpy result')\n",
    "axes[0].imshow(dst_res / 255)\n",
    "axes[1].set_title('OpenCV result')\n",
    "axes[1].imshow(cv_res / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=4, figsize=(15, 22))\n",
    "fig.tight_layout()\n",
    "\n",
    "ax_row_params = {'fontsize': 28, 'fontname': 'serif', 'labelpad': 15}\n",
    "ax_title_params = {'fontsize': 28, 'fontname': 'serif', 'pad': 15}\n",
    "\n",
    "ax[0][0].set_title('Blended Image', **ax_title_params)\n",
    "\n",
    "ax[0][1].set_title('Difference between\\nblended and original', **ax_title_params)\n",
    "\n",
    "for i, (method_name, blended_res, blended_res_diff) in enumerate(\n",
    "    [('Green\\'s function',              torch.movedim(res, 0, -1), torch.movedim(diff, 0, -1)),\n",
    "     ('Green\\'s function\\n over entire image', torch.movedim(res_wide, 0, -1), torch.movedim(diff_wide, 0, -1)),\n",
    "     ('Original OpenCV',                cv_res, cv_diff),\n",
    "     ('NumPy implementation\\n of OpenCV\\'s method', dst_res / 255, np.abs(cv_img_1 - dst_res).astype(int))]):\n",
    "    \n",
    "    ax[i][0].set_xticks([])\n",
    "    ax[i][0].set_yticks([])\n",
    "    ax[i][0].set_ylabel(method_name, **ax_row_params)\n",
    "    ax[i][0].imshow(blended_res)\n",
    "    \n",
    "\n",
    "    ax[i][1].set_xticks([])\n",
    "    ax[i][1].set_yticks([])\n",
    "    ax[i][1].imshow(blended_res_diff)\n",
    "    \n",
    "# fig.savefig('image_blending_comparison.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Poisson image editing over time and space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def read_gif(file_path):\n",
    "    return torch.stack([TF.to_tensor(im) for im in imageio.get_reader(file_path)])\n",
    "\n",
    "wave = read_gif('example_images/wave.gif')[:, :3]\n",
    "splat = read_gif('example_images/splat.gif')[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(torch.movedim(wave[0], 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_gif = wave\n",
    "\n",
    "source_gif = TF.resize(torch.cat([splat, torch.flip(splat, [0])]), [300, 300])\n",
    "\n",
    "corner_coord = torch.tensor([4, 100, 100])\n",
    "\n",
    "mask_gif = torch.ones((source_gif.shape[0], *source_gif.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "res_gif = pietorch.blend(target_gif, source_gif, mask_gif, corner_coord, True, channels_dim=1)\n",
    "print('Took ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(target_gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(torch.movedim(res_gif[10], 0, -1))\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(15, 15))\n",
    "fig.tight_layout()\n",
    "\n",
    "frames = [14, 20, 40]\n",
    "\n",
    "for j, f in enumerate(frames):\n",
    "    ax[0][j].set_title(f'Frame {f}', **ax_title_params)\n",
    "\n",
    "\n",
    "for i, (g_name, g) in enumerate([('Target', target_gif),\n",
    "                       ('Source', source_gif),\n",
    "                       ('Result', res_gif)]):\n",
    "    \n",
    "    ax[i][0].set_ylabel(g_name, **ax_row_params)\n",
    "\n",
    "    for j, f in enumerate(frames):\n",
    "        \n",
    "        ax[i][j].set_xticks([])\n",
    "        ax[i][j].set_yticks([])\n",
    "        offset = 4 if g_name == 'Source' else 0\n",
    "        ax[i][j].imshow(torch.movedim(g[f - offset], 0, -1))\n",
    "        \n",
    "# fig.savefig('gif_blending_comparison.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "gif = res_gif\n",
    "\n",
    "anim_fig, anim_ax = plt.subplots()\n",
    "anim_ax.set_axis_off()\n",
    "img_ax = plt.imshow(torch.movedim(gif[0], 0, -1))\n",
    "\n",
    "def animate_gif(frame_num):\n",
    "    img_ax.set_data(torch.movedim(gif[frame_num], 0, -1))\n",
    "    return img_ax\n",
    "\n",
    "anim =  FuncAnimation(anim_fig, animate_gif, frames=len(gif), interval=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# anim.save('example_images/blended.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Slice-wise OpenCV comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_gif_numpy(file_path: str) -> np.ndarray:\n",
    "    return np.stack([im for im in imageio.get_reader(file_path)])\n",
    "\n",
    "cv_wave = read_gif_numpy('example_images/wave.gif')[..., :3]\n",
    "cv_splat = read_gif_numpy('example_images/splat.gif')[..., :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv_wave[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cv_target_gif = cv_wave\n",
    "\n",
    "cv_source_gif = np.stack([cv2.resize(im, (300, 300)) for im in np.concatenate([cv_splat, np.flip(cv_splat, 0)])])\n",
    "\n",
    "cv_gif_first_frame = 4\n",
    "cv_gif_centre_coord = (250, 250)\n",
    "\n",
    "cv_mask_gif = np.ones((300, 300), dtype=np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_res_gif = cv_target_gif.copy()\n",
    "start = time()\n",
    "for source_frame in range(len(cv_source_gif)):\n",
    "    target_frame = cv_gif_first_frame + source_frame\n",
    "    cv_res_gif[target_frame] = cv2.seamlessClone(cv_source_gif[source_frame],\n",
    "                                                 cv_target_gif[target_frame],\n",
    "                                                 cv_mask_gif,\n",
    "                                                 cv_gif_centre_coord,\n",
    "                                                 cv2.MIXED_CLONE)\n",
    "print('Took ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "gif = cv_res_gif\n",
    "\n",
    "anim_fig, anim_ax = plt.subplots()\n",
    "anim_ax.set_axis_off()\n",
    "img_ax = plt.imshow(gif[0])\n",
    "\n",
    "def animate_gif(frame_num):\n",
    "    img_ax.set_data(gif[frame_num])\n",
    "    return img_ax\n",
    "\n",
    "anim =  FuncAnimation(anim_fig, animate_gif, frames=len(gif), interval=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# anim.save('example_images/cv_blended.gif', fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3D Poisson image editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "\n",
    "sitk_brain = sitk.ReadImage('example_images/brain.nii.gz')\n",
    "brain = sitk.GetArrayFromImage(sitk_brain)\n",
    "\n",
    "brain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(brain[100], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target_3d = torch.from_numpy(brain)\n",
    "\n",
    "source_3d = torch.zeros((100, 100, 100), dtype=torch.float64)\n",
    "mask_3d = torch.zeros_like(source_3d, dtype=torch.float64)\n",
    "radii = centre = np.array(source_3d.shape) // 2\n",
    "\n",
    "corner_3d = torch.tensor([78, 78, 78])\n",
    "\n",
    "for i in range(-radii[0], radii[0]):\n",
    "    for j in range(-radii[1], radii[1]):\n",
    "        for k in range(-radii[2], radii[2]):\n",
    "            distance = np.sqrt(i ** 2 + j ** 2 + k ** 2)\n",
    "            if distance <= 50:\n",
    "                coord = tuple(np.array([i, j, k]) + centre)\n",
    "                source_3d[coord] = np.sin(distance * np.pi / 5) / 4\n",
    "                mask_3d[coord] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(source_3d[70], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "res_3d = pietorch.blend(target_3d, source_3d, mask_3d, corner_3d, True)\n",
    "print('Took ', time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(res_3d[100], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_3d_sitk = sitk.GetImageFromArray(res_3d.numpy())\n",
    "\n",
    "res_3d_sitk.CopyInformation(sitk_brain)\n",
    "\n",
    "res_3d_sitk.GetSpacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sitk.WriteImage(res_3d_sitk, 'example_images/blended_brain.nii.gz')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}